# Domain/Orchestrator/pipeline.py
from __future__ import annotations

import logging
from typing import List

# üîπ FastAPI Ïä§Î†àÎìúÌíÄ Ïú†Ìã∏
from fastapi.concurrency import run_in_threadpool

# üîπ ÏµúÏã† ÏóîÏßÑ Î™®Îìà (backend/app/engine Ïïà)
# (Í≤ΩÎ°úÍ∞Ä ÎßûÎäîÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî. Î≥¥ÌÜµ app.engine ÎòêÎäî engine Îì±ÏúºÎ°ú ÏÑ§Ï†ïÎê®)
from engine.rag_engine import get_rag_context
from engine.rule_engine import calculate_rule_score
from engine.llm_analyzer import get_final_analysis_from_llm

# üîπ Orchestrator Ïú†Ìã∏ (ÏùëÎãµ Ïä§ÌÇ§Îßà + ÏïôÏÉÅÎ∏î)
from .ensemble_slot import combine_scores, _score_to_label
from .models import AnalyzeRequest, AnalyzeResult, RuleHit

logger = logging.getLogger(__name__)

# ==========================================
# ÌïµÏã¨ Î∂ÑÏÑù Î°úÏßÅ
# ==========================================
async def run_analyze(req: AnalyzeRequest) -> AnalyzeResult:
    """
    Orchestrator Í∏∞Ï§Ä + ÏµúÏã† ÏóîÏßÑ Í≤∞Ìï© ÌååÏù¥ÌîÑÎùºÏù∏
    """
    user_text = req.text

    # 1) RAG Í≤ÄÏÉâ ‚Äî ÎèôÍ∏∞ Ìï®ÏàòÎ•º Ïä§Î†àÎìúÌíÄÏóêÏÑú Ïã§Ìñâ
    try:
        contexts = await run_in_threadpool(
            get_rag_context,
            user_text,
            top_k=req.top_k,
        )
    except Exception as e:
        logger.exception("RAG Í≤ÄÏÉâ Ïã§Ìå®: %s", e)
        contexts = []

    # 2) Í∑úÏπô Í∏∞Î∞ò Ï†êÏàò ‚Äî ÎèôÍ∏∞ Ìï®Ïàò Ïä§Î†àÎìúÌíÄ Ïã§Ìñâ
    try:
        rule_score_raw = await run_in_threadpool(calculate_rule_score, user_text)
        rule_score = float(rule_score_raw)
    except Exception as e:
        logger.exception("Í∑úÏπô ÏóîÏßÑ Ïò§Î•ò: %s", e)
        rule_score = 0.0

    rule_hits: List[RuleHit] = []
    if rule_score > 0.0:
        rule_hits.append(
            RuleHit(
                category="RuleEngine",
                keyword_hits=[],
                regex_hits=[],
                weight=100.0,
                score=rule_score,
            )
        )

    # 3) LLM Î∂ÑÏÑù ‚Äî Í∞ÄÏû• Ïò§Îûò Í±∏Î¶¨Îäî Î∂ÄÎ∂Ñ
    llm_score = 0.0
    violated_law = ""
    analysis_text = ""
    try:
        llm_result = await run_in_threadpool(
            get_final_analysis_from_llm,
            user_text,
            contexts,
        )
        llm_score = float(llm_result.get("score_llm", 0.0))
        violated_law = llm_result.get("violated_law", "") or ""
        analysis_text = llm_result.get("analysis", "") or ""
    except Exception as e:
        logger.exception("LLM Î∂ÑÏÑù ÏóîÏßÑ Ïò§Î•ò: %s", e)

    # 4) ÏïôÏÉÅÎ∏î
    final_score = combine_scores(llm_score, rule_score, w_llm=0.7)
    final_label = _score_to_label(final_score)

    # 5) reasons Íµ¨ÏÑ±
    reasons: List[str] = []
    if violated_law:
        reasons.append(f"[Í¥ÄÎ†® Î≤ïÎ•†] {violated_law}")
    if analysis_text:
        reasons.append(analysis_text)

    # 6) Í≤∞Í≥º Ìå®ÌÇπ
    return AnalyzeResult(
        risk=final_label,
        score=final_score,
        llm_score=llm_score,
        rule_score=rule_score,
        rule_hits=rule_hits,
        reasons=reasons,
        rewrites=[],    
        contexts=contexts,
    )
