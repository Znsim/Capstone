# Domain/Orchestrator/pipeline.py
from __future__ import annotations

import logging
from typing import List

# ğŸ”¹ ìµœì‹  ì—”ì§„ ëª¨ë“ˆ (backend/app/engine ì•ˆ)
from engine.rag_engine import get_rag_context
from engine.rule_engine import calculate_rule_score
from engine.llm_analyzer import get_final_analysis_from_llm

# ğŸ”¹ Orchestrator ìœ í‹¸ (ì‘ë‹µ ìŠ¤í‚¤ë§ˆ + ì•™ìƒë¸”)
from .ensemble_slot import combine_scores, _score_to_label
from .models import AnalyzeRequest, AnalyzeResult, RuleHit


logger = logging.getLogger(__name__)


async def run_analyze(req: AnalyzeRequest) -> AnalyzeResult:
    """
    Orchestrator ê¸°ì¤€ + ìµœì‹  ì—”ì§„ ê²°í•© íŒŒì´í”„ë¼ì¸

    1) engine.rag_engine â†’ RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    2) engine.rule_engine â†’ ê·œì¹™ ì ìˆ˜ ê³„ì‚°
    3) engine.llm_analyzer â†’ LLM ì ìˆ˜ / ë²•ë¥  / ë¶„ì„ ë°›ê¸°
    4) ensemble_slot.combine_scores â†’ ìµœì¢… score ê³„ì‚°
    5) score â†’ risk ë¼ë²¨ ë§¤í•‘ (_score_to_label)
    6) AnalyzeResult í˜•íƒœë¡œ ì‘ë‹µ
    """
    user_text = req.text

    # 1) RAG ê²€ìƒ‰ (ë™ê¸° í•¨ìˆ˜ë¼ ê·¸ëƒ¥ í˜¸ì¶œ)
    try:
        contexts = get_rag_context(user_text, top_k=req.top_k)
    except Exception as e:
        logger.exception("RAG ê²€ìƒ‰ ì‹¤íŒ¨: %s", e)
        contexts = []

    # 2) ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ (0.0 ë˜ëŠ” 1.0)
    try:
        rule_score = float(calculate_rule_score(user_text))
    except Exception as e:
        logger.exception("ê·œì¹™ ì—”ì§„ ì˜¤ë¥˜: %s", e)
        rule_score = 0.0

    rule_hits: List[RuleHit] = []
    if rule_score > 0.0:
        # ì¹´í…Œê³ ë¦¬/íˆíŠ¸ ìƒì„¸ê¹Œì§€ëŠ” rule_engineì— ì—†ìœ¼ë¯€ë¡œ ìµœì†Œ ì •ë³´ë§Œ ì±„ì›€
        rule_hits.append(
            RuleHit(
                category="RuleEngine",
                keyword_hits=[],
                regex_hits=[],
                weight=100.0,
                score=rule_score,
            )
        )

    # 3) LLM ë¶„ì„
    llm_score = 0.0
    violated_law = ""
    analysis_text = ""
    try:
        llm_result = get_final_analysis_from_llm(user_text, contexts)
        llm_score = float(llm_result.get("score_llm", 0.0))
        violated_law = llm_result.get("violated_law", "") or ""
        analysis_text = llm_result.get("analysis", "") or ""
    except Exception as e:
        logger.exception("LLM ë¶„ì„ ì—”ì§„ ì˜¤ë¥˜: %s", e)

    # 4) ì•™ìƒë¸” (0.7 * LLM + 0.3 * RULE) â€” ê¸°ì¡´ ê·œì¹™ ìœ ì§€
    final_score = combine_scores(llm_score, rule_score, w_llm=0.7)
    final_label = _score_to_label(final_score)

    # 5) reasons êµ¬ì„±
    reasons: List[str] = []
    if violated_law:
        reasons.append(f"[ê´€ë ¨ ë²•ë¥ ] {violated_law}")
    if analysis_text:
        reasons.append(analysis_text)

    # 6) ê²°ê³¼ íŒ¨í‚¹
    return AnalyzeResult(
        risk=final_label,
        score=final_score,
        llm_score=llm_score,
        rule_score=rule_score,
        rule_hits=rule_hits,
        reasons=reasons,
        rewrites=[],   # llm_analyzerëŠ” rewrites ì•ˆ ì£¼ë‹ˆê¹Œ ì¼ë‹¨ ë¹„ì›€
        contexts=contexts,
    )
